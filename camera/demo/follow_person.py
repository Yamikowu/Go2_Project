#!/usr/bin/env python3
"""
ğŸš¶â€â™‚ï¸ äººç‰©è·Ÿéš¨æ¨¡æ“¬å™¨ (Follow Person Simulator)

åŸºæ–¼æ·±åº¦æ”å½±æ©Ÿçš„è·Ÿéš¨åŠŸèƒ½ï¼š
- é–å®šç•«é¢ä¸­æœ€è¿‘çš„ç‰©é«”ï¼ˆå‡è¨­æ˜¯äººï¼‰
- å¤ªè¿‘ â†’ åœä¸‹
- å¤ªé  â†’ è·Ÿä¸Š
- å·¦å³åç§» â†’ è½‰å‘ä¿®æ­£ 
ä½¿ç”¨æ–¹å¼:
sudo /Users/yamiko/Documents/VsCode/Go2_Project/.venv/bin/python /Users/yamiko/Documents/VsCode/Go2_Project/camera/demo/follow_person.py
"""
import pyrealsense2 as rs
import numpy as np
import cv2
import sys
import os

# åŠ å…¥ utils è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from utils.perf_monitor import PerfMonitor, print_system_info

# ===== è·Ÿéš¨åƒæ•¸ =====
STOP_DISTANCE = 0.6      # å°æ–¼ 60cm = å¤ªè¿‘ï¼Œåœä¸‹
FOLLOW_DISTANCE = 1.2    # å¤§æ–¼ 120cm = å¤ªé ï¼Œè·Ÿä¸Š
IDEAL_DISTANCE = 0.9     # ç†æƒ³è·é›¢ 90cmï¼ˆç”œèœœé»ä¸­å¿ƒï¼‰
MAX_DISTANCE = 3.0       # æœ€å¤§åµæ¸¬è·é›¢

# ===== è½‰å‘åƒæ•¸ =====
CENTER_DEADZONE = 30     # ä¸­å¿ƒæ­»å€ï¼ˆåƒç´ ï¼‰ï¼Œåœ¨é€™ç¯„åœå…§ä¸è½‰å‘ (é™ä½=æ›´éˆæ•)
MAX_ANGULAR_Z = 0.6      # æœ€å¤§è½‰å‘é€Ÿåº¦ (rad/s)
ANGULAR_GAIN = 0.005     # è½‰å‘å¢ç›Š (æé«˜=æ›´å¿«åæ‡‰)

# ===== åµæ¸¬åƒæ•¸ =====
ROI_WIDTH = 300          # åµæ¸¬å€åŸŸå¯¬åº¦ (åŠ å¤§=æ›´å®¹æ˜“è¿½è¹¤)
ROI_HEIGHT = 350         # åµæ¸¬å€åŸŸé«˜åº¦ï¼ˆç¸±å‘è¼ƒå¤§ï¼Œé©åˆåµæ¸¬äººï¼‰
MIN_BLOB_SIZE = 3000     # æœ€å°ç‰©é«”é¢ç©ï¼ˆéæ¿¾é›œè¨Šï¼Œé™ä½=æ›´éˆæ•ï¼‰
SEARCH_MARGIN = 100      # æœå°‹ç¯„åœé‚Šè·ï¼ˆé¿é–‹ç•«é¢é‚Šç·£é›œè¨Šï¼‰


def find_target(depth_image, depth_scale):
    """
    æ‰¾åˆ°ç•«é¢ä¸­å¤®å€åŸŸå…§æœ€è¿‘çš„ç‰©é«”ï¼ˆå‡è¨­æ˜¯äººï¼‰
    
    ç­–ç•¥ï¼š
    1. å„ªå…ˆçœ‹ç•«é¢ä¸­å¤®å€åŸŸ
    2. ç”¨åŠ æ¬Šæ–¹å¼ï¼Œè®“è¶Šé è¿‘ä¸­å¤®çš„ç‰©é«”å„ªå…ˆè¢«é¸ä¸­
    
    Returns:
        center_x: ç›®æ¨™ä¸­å¿ƒ X åº§æ¨™ï¼ˆç•«é¢åº§æ¨™ï¼‰
        center_y: ç›®æ¨™ä¸­å¿ƒ Y åº§æ¨™
        distance: ç›®æ¨™è·é›¢ï¼ˆå…¬å°ºï¼‰
        blob_size: ç‰©é«”å¤§å°ï¼ˆåƒç´ æ•¸ï¼‰
    """
    h, w = depth_image.shape
    cx, cy = w // 2, h // 2
    
    # è½‰æ›æˆå…¬å°º
    depth_meters = depth_image.astype(np.float32) * depth_scale
    
    # åªçœ‹æœ‰æ•ˆè·é›¢å…§çš„ç‰©é«”ï¼ˆæ’é™¤å¤ªè¿‘å’Œå¤ªé ï¼‰
    valid_mask = (depth_meters > 0.2) & (depth_meters < MAX_DISTANCE)
    
    # æ’é™¤ç•«é¢é‚Šç·£ï¼ˆé€šå¸¸æ˜¯ç‰†å£ï¼‰
    edge_mask = np.ones_like(valid_mask)
    edge_mask[:SEARCH_MARGIN, :] = False  # ä¸Šé‚Š
    edge_mask[-SEARCH_MARGIN:, :] = False  # ä¸‹é‚Š
    edge_mask[:, :SEARCH_MARGIN] = False   # å·¦é‚Š
    edge_mask[:, -SEARCH_MARGIN:] = False  # å³é‚Š
    valid_mask = valid_mask & edge_mask
    
    if not np.any(valid_mask):
        return None, None, 0, 0
    
    # å»ºç«‹ã€Œä¸­å¤®åå¥½ã€æ¬Šé‡åœ–
    # è¶Šé è¿‘ä¸­å¤®æ¬Šé‡è¶Šé«˜ï¼Œé€™æ¨£å³ä½¿æ—é‚Šæœ‰æ›´è¿‘çš„ç‰†å£ï¼Œä¹Ÿæœƒå„ªå…ˆé¸ä¸­å¤®çš„äºº
    y_coords, x_coords = np.mgrid[0:h, 0:w]
    dist_to_center = np.sqrt((x_coords - cx)**2 + (y_coords - cy)**2)
    center_weight = 1.0 - (dist_to_center / (np.sqrt(cx**2 + cy**2)))  # 0~1
    center_weight = np.clip(center_weight, 0.3, 1.0)  # æœ€å°æ¬Šé‡ 0.3
    
    # è¨ˆç®—ã€Œç¶œåˆåˆ†æ•¸ã€= è·é›¢è¿‘ + é è¿‘ä¸­å¤®
    # åˆ†æ•¸è¶Šä½è¶Šå¥½
    score = np.where(valid_mask,
                     depth_meters / center_weight,  # è·é›¢ / æ¬Šé‡
                     np.inf)
    
    # æ‰¾åˆ†æ•¸æœ€ä½çš„å€åŸŸï¼ˆæœ€è¿‘ä¸”æœ€é è¿‘ä¸­å¤®ï¼‰
    threshold_score = np.percentile(score[valid_mask], 15)  # æœ€ä½³ 15%
    best_mask = (score <= threshold_score) & valid_mask
    
    # éæ¿¾å¤ªå°çš„å€åŸŸ
    blob_size = np.sum(best_mask)
    if blob_size < MIN_BLOB_SIZE:
        return None, None, 0, 0
    
    # è¨ˆç®—é‡å¿ƒ
    target_y_coords, target_x_coords = np.where(best_mask)
    center_x = int(np.mean(target_x_coords))
    center_y = int(np.mean(target_y_coords))
    
    # è¨ˆç®—ç›®æ¨™è·é›¢ï¼ˆè©²å€åŸŸçš„ä¸­ä½æ•¸è·é›¢ï¼‰
    target_distance = np.median(depth_meters[best_mask])
    
    return center_x, center_y, target_distance, blob_size


def get_follow_command(distance, offset_x, frame_width):
    """
    æ ¹æ“šè·é›¢å’Œåç§»é‡æ±ºå®šè·Ÿéš¨æŒ‡ä»¤
    
    Args:
        distance: ç›®æ¨™è·é›¢ï¼ˆå…¬å°ºï¼‰
        offset_x: ç›®æ¨™ç›¸å°æ–¼ç•«é¢ä¸­å¿ƒçš„åç§»ï¼ˆåƒç´ ï¼Œæ­£=å³ï¼Œè² =å·¦ï¼‰
        frame_width: ç•«é¢å¯¬åº¦
    
    Returns:
        linear_x: å‰é€²é€Ÿåº¦ (æ­£=å‰é€², è² =å¾Œé€€, 0=åœæ­¢)
        angular_z: è½‰å‘é€Ÿåº¦ (æ­£=å·¦è½‰, è² =å³è½‰)
        action: å‹•ä½œåç¨±
        message: é¡¯ç¤ºè¨Šæ¯
        color: UI é¡è‰²
    """
    # === å‰é€²/åœæ­¢é‚è¼¯ ===
    if distance <= 0 or distance > MAX_DISTANCE:
        linear_x = 0
        action = "SEARCH"
        message = "ğŸ” æœå°‹ç›®æ¨™ä¸­..."
        color = (128, 128, 128)  # ç°è‰²
    elif distance < STOP_DISTANCE:
        linear_x = 0
        action = "STOP"
        message = f"ğŸ›‘ å¤ªè¿‘äº†ï¼åœä¸‹ ({distance:.2f}m)"
        color = (0, 0, 255)  # ç´…è‰²
    elif distance > FOLLOW_DISTANCE:
        # è·é›¢è¶Šé ï¼Œé€Ÿåº¦è¶Šå¿«ï¼ˆä½†æœ‰ä¸Šé™ï¼‰
        linear_x = min(0.5, (distance - IDEAL_DISTANCE) * 0.3)
        action = "FOLLOW"
        message = f"ğŸƒ è·Ÿä¸Šï¼({distance:.2f}m)"
        color = (0, 255, 0)  # ç¶ è‰²
    else:
        linear_x = 0
        action = "KEEP"
        message = f"âœ… ä¿æŒè·é›¢ ({distance:.2f}m)"
        color = (255, 165, 0)  # æ©™è‰²
    
    # === è½‰å‘é‚è¼¯ ===
    if abs(offset_x) < CENTER_DEADZONE:
        angular_z = 0
    else:
        # åå³ â†’ è² å€¼ï¼ˆå³è½‰è¿½éå»ï¼‰
        # åå·¦ â†’ æ­£å€¼ï¼ˆå·¦è½‰è¿½éå»ï¼‰
        angular_z = -offset_x * ANGULAR_GAIN
        angular_z = np.clip(angular_z, -MAX_ANGULAR_Z, MAX_ANGULAR_Z)
    
    # è½‰å‘æ™‚æ›´æ–°è¨Šæ¯
    if angular_z != 0:
        direction = "â¬…ï¸ å·¦è½‰" if angular_z > 0 else "â¡ï¸ å³è½‰"
        message += f" | {direction}"
    
    return linear_x, angular_z, action, message, color


def draw_follow_ui(frame, target_x, target_y, distance, blob_size, 
                   linear_x, angular_z, action, message, color):
    """ç¹ªè£½è·Ÿéš¨ UI"""
    h, w = frame.shape[:2]
    cx, cy = w // 2, h // 2
    
    # ç¹ªè£½ç›®æ¨™è¿½è¹¤æ¡†
    if target_x is not None:
        # æ ¹æ“š blob_size ä¼°ç®—æ¡†å¤§å°
        box_size = int(np.sqrt(blob_size) * 0.5)
        box_size = max(50, min(200, box_size))
        
        cv2.rectangle(frame, 
                      (target_x - box_size // 2, target_y - box_size // 2),
                      (target_x + box_size // 2, target_y + box_size // 2),
                      color, 3)
        
        # ç•«ç·šé€£æ¥ç›®æ¨™å’Œç•«é¢ä¸­å¿ƒ
        cv2.line(frame, (cx, cy), (target_x, target_y), color, 2)
        
        # æ¨™è¨˜ç›®æ¨™ä¸­å¿ƒ
        cv2.circle(frame, (target_x, target_y), 8, color, -1)
    
    # ç•«é¢ä¸­å¿ƒåå­—
    cv2.line(frame, (cx - 20, cy), (cx + 20, cy), (255, 255, 255), 1)
    cv2.line(frame, (cx, cy - 20), (cx, cy + 20), (255, 255, 255), 1)
    
    # æ­»å€ç¯„åœ
    cv2.rectangle(frame, 
                  (cx - CENTER_DEADZONE, 50),
                  (cx + CENTER_DEADZONE, h - 50),
                  (100, 100, 100), 1)
    
    # === å·¦å´ï¼šè·é›¢æ¢ ===
    bar_x, bar_w, bar_h = 30, 30, h - 100
    bar_y = 50
    
    cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_w, bar_y + bar_h), (50, 50, 50), -1)
    
    if distance > 0 and distance <= MAX_DISTANCE:
        fill_ratio = 1.0 - (distance / MAX_DISTANCE)
        fill_h = int(bar_h * fill_ratio)
        cv2.rectangle(frame, (bar_x, bar_y + bar_h - fill_h),
                      (bar_x + bar_w, bar_y + bar_h), color, -1)
    
    # æ¨™è¨˜é–¾å€¼
    stop_y = bar_y + bar_h - int(bar_h * (STOP_DISTANCE / MAX_DISTANCE))
    follow_y = bar_y + bar_h - int(bar_h * (FOLLOW_DISTANCE / MAX_DISTANCE))
    cv2.line(frame, (bar_x - 5, stop_y), (bar_x + bar_w + 5, stop_y), (0, 0, 255), 2)
    cv2.line(frame, (bar_x - 5, follow_y), (bar_x + bar_w + 5, follow_y), (0, 255, 0), 2)
    
    # === å³å´ï¼šé€Ÿåº¦æŒ‡ç¤º ===
    # å‰é€²é€Ÿåº¦ç®­é ­
    arrow_x = w - 60
    arrow_cy = h // 2
    if linear_x > 0:
        arrow_len = int(linear_x * 100)
        cv2.arrowedLine(frame, (arrow_x, arrow_cy), (arrow_x, arrow_cy - arrow_len),
                        (0, 255, 0), 3, tipLength=0.3)
        cv2.putText(frame, f"{linear_x:.2f}", (arrow_x - 25, arrow_cy - arrow_len - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
    
    # è½‰å‘ç®­é ­
    if angular_z != 0:
        turn_x = w - 120
        turn_len = int(abs(angular_z) * 80)
        if angular_z > 0:  # å·¦è½‰
            cv2.arrowedLine(frame, (turn_x, arrow_cy), (turn_x - turn_len, arrow_cy),
                            (255, 255, 0), 3, tipLength=0.3)
        else:  # å³è½‰
            cv2.arrowedLine(frame, (turn_x, arrow_cy), (turn_x + turn_len, arrow_cy),
                            (255, 255, 0), 3, tipLength=0.3)
    
    # === åº•éƒ¨è³‡è¨Šï¼ˆäººè®€ï¼‰ ===
    # ä¸»è¨Šæ¯ï¼ˆå«ç®­é ­ï¼‰- å¤§å­—
    # å› ç‚º OpenCV ä¸æ”¯æ´ emojiï¼Œç”¨æ–‡å­—ä»£æ›¿
    if angular_z > 0:
        turn_text = "<< LEFT"
    elif angular_z < 0:
        turn_text = "RIGHT >>"
    else:
        turn_text = ""
    
    # å‹•ä½œè¨Šæ¯
    if action == "SEARCH":
        action_text = "SEARCHING..."
    elif action == "STOP":
        action_text = f"STOP! Too close ({distance:.2f}m)"
    elif action == "FOLLOW":
        action_text = f"FOLLOW! ({distance:.2f}m)"
    else:
        action_text = f"KEEP ({distance:.2f}m)"
    
    # é¡¯ç¤ºä¸»è¨Šæ¯
    cv2.putText(frame, action_text, (w // 2 - 120, h - 55),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    
    # é¡¯ç¤ºè½‰å‘
    if turn_text:
        cv2.putText(frame, turn_text, (w // 2 + 100, h - 55),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
    
    # æ©Ÿå™¨æ•¸æ“šï¼ˆå°å­—ï¼Œçµ¦é–‹ç™¼è€…åƒè€ƒï¼‰
    cv2.putText(frame, f"x:{linear_x:.2f} z:{angular_z:.2f}",
                (w // 2 - 60, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
    
    # é ‚éƒ¨æ¨™é¡Œ
    cv2.putText(frame, "Follow Person Simulator", (w // 2 - 130, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)
    
    return frame


def main():
    print("=" * 50)
    print("ğŸš¶â€â™‚ï¸ äººç‰©è·Ÿéš¨æ¨¡æ“¬å™¨ (Follow Person Simulator)")
    print("=" * 50)
    print(f"ğŸ“ è·é›¢è¨­å®š:")
    print(f"   < {STOP_DISTANCE}m = åœä¸‹ (STOP)")
    print(f"   {STOP_DISTANCE}m ~ {FOLLOW_DISTANCE}m = ä¿æŒ (KEEP)")
    print(f"   > {FOLLOW_DISTANCE}m = è·Ÿä¸Š (FOLLOW)")
    print(f"ğŸ¯ è½‰å‘æ­»å€: Â±{CENTER_DEADZONE} åƒç´ ")
    print("=" * 50)
    
    print_system_info()
    monitor = PerfMonitor("FollowPerson")
    monitor.start()
    
    # åˆå§‹åŒ–ç›¸æ©Ÿ
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
    
    try:
        profile = pipeline.start(config)
        depth_sensor = profile.get_device().first_depth_sensor()
        depth_scale = depth_sensor.get_depth_scale()
        
        print(f"âœ… ç›¸æ©Ÿå•Ÿå‹•æˆåŠŸï¼æ·±åº¦å–®ä½: {depth_scale}")
        print("ğŸ‘‰ ç«™åœ¨ç›¸æ©Ÿå‰é¢è©¦è©¦çœ‹ï¼")
        print("ğŸ‘‰ æŒ‰ 'q' é›¢é–‹")
        
        # è·³éå‰å¹¾å¹€è®“ç›¸æ©Ÿç©©å®š
        for _ in range(30):
            pipeline.wait_for_frames()
        
        frame_count = 0
        
        while True:
            frames = pipeline.wait_for_frames()
            depth_frame = frames.get_depth_frame()
            
            if not depth_frame:
                continue
            
            depth_image = np.asanyarray(depth_frame.get_data())
            h, w = depth_image.shape
            
            # æ‰¾ç›®æ¨™
            target_x, target_y, distance, blob_size = find_target(depth_image, depth_scale)
            
            # è¨ˆç®—åç§»é‡
            if target_x is not None:
                offset_x = target_x - (w // 2)
            else:
                offset_x = 0
            
            # æ±ºå®šæŒ‡ä»¤
            linear_x, angular_z, action, message, color = get_follow_command(
                distance, offset_x, w
            )
            
            # è¦–è¦ºåŒ–
            depth_colormap = cv2.applyColorMap(
                cv2.convertScaleAbs(depth_image, alpha=0.03),
                cv2.COLORMAP_JET
            )
            
            # ç¹ªè£½ UI
            ui_frame = draw_follow_ui(
                depth_colormap, target_x, target_y, distance, blob_size,
                linear_x, angular_z, action, message, color
            )
            
            cv2.imshow('Follow Person (Press Q to Exit)', ui_frame)
            
            # çµ‚ç«¯æ©Ÿè¼¸å‡ºï¼ˆæ©Ÿå™¨å¯è®€æ ¼å¼ï¼‰
            print(f"\r[{action}] dist:{distance:.2f} x:{linear_x:.2f} z:{angular_z:.2f} blob:{blob_size}", end="", flush=True)
            
            # æ•ˆèƒ½ç›£æ§
            frame_count += 1
            monitor.log(interval=60)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                print("\nğŸ‘‹ é›¢é–‹ä¸­...")
                break
    
    except RuntimeError as e:
        print(f"âŒ éŒ¯èª¤: {e}")
    
    finally:
        try:
            pipeline.stop()
        except:
            pass
        cv2.destroyAllWindows()
        monitor.report()
        print("ç¨‹å¼çµæŸ")


if __name__ == "__main__":
    main()
